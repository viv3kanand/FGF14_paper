---
title: "Test"
author: "viv3kanand"
date: "2023-11-01"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## load packages
```{r}
require(tidyverse)
```

## Batch process STRique data
```{r}
source("../scripts/GMM.R")

file_paths <- list.files("../data/out/", full.names = TRUE)

result_list <- lapply(
  setNames(file_paths, str_remove(basename(file_paths), ".hg19.strique.tsv")), 
  function(file_path){
    process_result <- process_file(file_path)
    return(process_result)
})

saveRDS(result_list, file = "results/RData/result_list.RData")
```


### Frequency estimation for each cluster based on mode
```{r}
result_mode <- lapply(result_list, function(result) result$mode) %>% 
  Reduce(function(...) merge(..., all=T), .) %>% 
  pivot_wider(names_from = allele, values_from = c(mode_repeat, repeat_freq, allele_freq, prop))


FGF14 <- read.csv("../data/FGF14-sample data.csv")
result_mode <- merge(FGF14, result_mode, by.x = "barcode", by.y = "id")

saveRDS(result_mode, file = "results/RData/result_mode.RData")

write.csv(result_mode, paste0("results/", Sys.Date(), "_FGF14_result.csv"))

```


### Interruption analysis
```{r}
result_df <- lapply(result_list, function(result) result$df)

# omit barcode01 and barcode02 for not having enough read count to support downstream analysis

clusters <- list(
  barcode04 = c(3),
  barcode13 = c(3,5),
  barcode14 = c(4,5),
  barcode15 = c(4,6),
  barcode25 = c(2,5),
  barcode26 = c(3,6),
  barcode27 = c(4,6),
  barcode37 = c(3,6),
  barcode38 = c(3,8),
  barcode39 = c(3,6),
  barcode49 = c(2,5),
  barcode50 = c(4,6),
  barcode51 = c(4,8),
  barcode61 = c(6,8),
  barcode62 = c(1,3),
  barcode63 = c(5),
  barcode73 = c(2,4),
  barcode74 = c(2,3),
  barcode75 = c(2,4),
  barcode85 = c(2,5),
  barcode87 = c(2,6))

# subset clusters from result_df with upstream and downstream from mode (+20 | -20)
lapply(setNames(seq_along(1:length(clusters)), names(clusters)), function(barcode){
    result_df[names(clusters)][[barcode]] %>% 
    filter(allele %in% clusters[[barcode]]) %>% 
    group_by(allele) %>% 
    arrange(count) %>% 
    mutate(allele_ref = paste0("allele_", cur_group_id()),
           mode = as.numeric(names(sort(table(count), decreasing = TRUE)[1])),
           flanking = case_when(count <= mode & count >= mode-20 ~ "upstream",
                                count >= mode & count <= mode+20 ~ "downstream",
                                TRUE ~ "NA"),
           consensus = case_when(count == mode ~ "mode",
                                 count >= max(count)-20 ~ "max",
                                TRUE ~ "NA")) %>% 
    ungroup()
}) -> df_subset


saveRDS(df_subset, file = "results/RData/df_subset.RData")
```

### Write read ids to file
```{r}
# subset fastq id for fetching sequence based on mode
lapply(df_subset, function(df){
  name <- df$id %>% unique()
  
  df_a1 <- df %>% 
    filter(allele_ref == "allele_1" & consensus == "mode") %>%
    select(ID)
  
  df_a2 <- df %>% 
    filter(allele_ref == "allele_2" & consensus == "mode") %>% 
    select(ID)
  
  write_csv(df_a1, file = paste0("results/mode/A1/", name))
  write_csv(df_a2, file = paste0("results/mode/A2/", name))
})

# subset fastq id for fetching sequence based on flanking
lapply(df_subset, function(df){
  name <- df$id %>% unique()
  
  df_a1 <- df %>% 
    filter(allele_ref == "allele_1" & flanking %in% c("upstream", "downstream")) %>%
    select(ID)
  
  df_a2 <- df %>% 
    filter(allele_ref == "allele_2" & flanking %in% c("upstream", "downstream")) %>% 
    select(ID)
  
  write_csv(df_a1, file = paste0("results/flanking/A1/", name))
  write_csv(df_a2, file = paste0("results/flanking/A2/", name))
})

```






















