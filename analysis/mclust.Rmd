---
title: "Test"
author: "viv3kanand"
date: "2023-11-01"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Batch process STRique data
```{r}
source("../scripts/GMM.R")

file_paths <- list.files("../data/out/", full.names = TRUE)

result_list <- lapply(
  setNames(file_paths, str_remove(basename(file_paths), ".hg19.strique.tsv")), 
  function(file_path){
    process_result <- process_file(file_path)
    return(process_result)
})

result_mode <- lapply(result_list, function(result) result$mode) %>% 
  Reduce(function(...) merge(..., all=T), .) %>% 
  pivot_wider(names_from = allele, values_from = c(mode_repeat, repeat_freq, allele_freq, prop))


FGF14 <- read.csv("../data/FGF14-sample data.csv")
result_mode <- merge(FGF14, result_mode, by.x = "barcode", by.y = "id")


write.csv(result_mode, paste0("results/", Sys.Date(), "_FGF14_result.csv"))

```


### Interruptions
```{r}
result_df <- lapply(result_list, function(result) result$df)

# omit barcode01 and barcode02 for not having enough read count to support downstream analysis

clusters <- list(
  barcode04 = c(3),
  barcode13 = c(3,5),
  barcode14 = c(4,5),
  barcode15 = c(4,6),
  barcode25 = c(2,5),
  barcode26 = c(3,6),
  barcode27 = c(4,6),
  barcode37 = c(3,6),
  barcode38 = c(3,8),
  barcode39 = c(3,6),
  barcode49 = c(2,5),
  barcode50 = c(4,6),
  barcode51 = c(4,8),
  barcode61 = c(6,8),
  barcode62 = c(1,3),
  barcode63 = c(5),
  barcode73 = c(2,4),
  barcode74 = c(2,3),
  barcode75 = c(2,4),
  barcode85 = c(2,5),
  barcode87 = c(2,6))

# subset clusters from result_df with upstream and downstream from mode (+20 | -20)
lapply(setNames(seq_along(1:length(clusters)), names(clusters)), function(barcode){
    result_df[names(clusters)][[barcode]] %>% 
    filter(allele %in% clusters[[barcode]]) %>% 
    group_by(allele) %>% 
    arrange(count) %>% 
    mutate(allele_ref = paste0("allele_", cur_group_id()),
           mode = as.numeric(names(sort(table(count), decreasing = TRUE)[1])),
           flanking = case_when(count <= mode & count >= mode-20 ~ "upstream",
                                count >= mode & count <= mode+20 ~ "downstream",
                                TRUE ~ "NA"),
           consensus = case_when(count == mode ~ "mode",
                                 count >= max(count)-20 ~ "max",
                                TRUE ~ "NA")) %>% 
    ungroup()
}) -> df_subset



# subset fastq id for fetching sequence based on mode
lapply(df_subset, function(df){
  name <- df$id %>% unique()
  
  df_a1 <- df %>% 
    filter(allele_ref == "allele_1" & consensus == "mode") %>%
    select(ID)
  
  df_a2 <- df %>% 
    filter(allele_ref == "allele_2" & consensus == "mode") %>% 
    select(ID)
  
  write_csv(df_a1, file = paste0("results/mode/A1/", name))
  write_csv(df_a2, file = paste0("results/mode/A2/", name))
})

# subset fastq id for fetching sequence based on flanking
lapply(df_subset, function(df){
  name <- df$id %>% unique()
  
  df_a1 <- df %>% 
    filter(allele_ref == "allele_1" & flanking %in% c("upstream", "downstream")) %>%
    select(ID)
  
  df_a2 <- df %>% 
    filter(allele_ref == "allele_2" & flanking %in% c("upstream", "downstream")) %>% 
    select(ID)
  
  write_csv(df_a1, file = paste0("results/flanking/A1/", name))
  write_csv(df_a2, file = paste0("results/flanking/A2/", name))
})



```


### Figure
```{r}
# summary of the cluster distribution
lapply(df_subset, function(df){
  df %>% 
    group_by(id, allele_ref) %>% 
    summarise(mode = as.numeric(names(sort(table(count), decreasing = TRUE)[1])),
              freq = max(table(count)),
              .groups = 'drop')
}) %>% 
  Reduce(function(...) merge(..., all=T), .) %>% 
  pivot_wider(names_from = allele_ref, values_from = c(mode, freq)) -> mode_df





df_merged <- df_subset %>% Reduce(function(...) merge(..., all=T), .)


ggplot(df_merged, aes(x = count, fill = factor(allele_ref))) +
    geom_density(alpha = 0.5) +
    scale_fill_manual(values = c("red", "blue")) +
    theme_minimal() + 
    facet_wrap(~id, scales = "free")




# Heatmap of all clusters
heatmap_dat <- result_df %>% 
  Reduce(function(...) merge(..., all=T), .) %>% 
  group_by(id, count) %>%
  summarise(freq = n(), .groups = 'drop') %>%
  pivot_wider(names_from = count, values_from = freq) %>% 
  tibble::column_to_rownames("id")

mat <- t(apply(as.matrix(heatmap_dat), 1, function(x) (x - mean(x, na.rm = TRUE))/sd(x, na.rm = TRUE)))

mat <- mat[,order(as.numeric(as.character(colnames(mat))))]

myCol <- colorRampPalette(c('black','white', 'red'))(50)
myBreaks <- seq(-3, 3, length.out = 50)
col_fun <- colorRamp2(myBreaks, myCol)

#col_fun <- colorRamp2(c(-2, 5), c("white", "red"))

num_bins = 50
ha = columnAnnotation(
  foo = anno_mark(
    at = seq(1, ncol(mat) + num_bins, by = num_bins),
    labels = colnames(mat)[seq(1, ncol(mat) + num_bins, by = num_bins)]))

# breaks <- mode_df %>%
#   pivot_longer(cols = c("allele_1", "allele_2")) %>%
#   pull(value) %>%
#   sort %>%
#   unique()

# ha =columnAnnotation(foo = anno_mark(
#   at = c(10,25,60,85,112,123,137,246,270,295,321,366,404,428), 
#   labels = c(10,25,60,85,112,123,137,246,270,295,321,366,404,428)))


heatmap <- ComplexHeatmap::Heatmap(mat,
                                   na_col = "white",
                                   cluster_rows = FALSE, 
                                   cluster_columns = FALSE,
                                   col = col_fun,
                                   top_annotation = ha,
                                   row_split = 1:25,
                                   row_title = NULL,
                                   row_names_side = "left",
                                   show_row_names = TRUE,
                                   show_column_names = FALSE,
                                   border_gp = gpar(col = "black", lwd = 1),
                                   name = "z-score")


png("figures/heatmap.png", width = 10, height = 8, units = "in", res = 300)
draw(heatmap)
dev.off()
```

























