---
title: "Test"
author: "viv3kanand"
date: "2023-11-01"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(mclust) # For fitting GMM
library(openxlsx)
library(ComplexHeatmap)
### Evaluating clusters
#renv::install("ramey/clusteval")
#renv::install("factoextra")
```

```{r}
file1 <- "../data/out/barcode03.hg19.strique.tsv"
file2 <- "../data/out/barcode86.hg19.strique.tsv"

df1 <- read.table(file1, header = TRUE)
df2 <- read.table(file2, header = TRUE)

df <- rbind(df1,df2)

#file <- "../data/out/barcode02.hg19.strique.tsv"
#df <- read.table(file, header = TRUE)

df %>% filter(count > 3 & score_prefix >= 4 & score_suffix >= 4) -> df
set.seed(666)
fit <- Mclust(df$count)

prob <- predict(fit)

df$allele <- apply(prob$z, 1, which.max)
df$id <- str_remove(basename(file), ".hg19.strique.tsv")

mode_df <- df %>%
    group_by(id, allele) %>%
    summarise(allele_freq = n(),
              mode_repeat = as.numeric(names(sort(table(count), decreasing = TRUE)[1])),
              repeat_freq = max(table(count)),
              prop = repeat_freq/allele_freq)

mode_df %>% arrange(allele_freq)


```


```{r}
ggplot(df, aes(x = count, fill = factor(allele))) +
    geom_density(alpha = 0.5) +
    scale_fill_manual(values = c("red", "blue", "green")) +
    theme_minimal() +
    geom_vline(xintercept = c(mode_df$mode_repeat[2], mode_df$mode_repeat[3]), linetype = "dashed")
```



```{r}
FGF14 <- read.csv("../data/FGF14-sample data.csv")

file_paths <- list.files("../data/out/", full.names = TRUE)

result_df <- data.frame()

process_file <- function(file_path) {
  df <- read.table(file_path, header = TRUE)
  
  df_filtered <- df %>%
    filter(count > 3, score_prefix >= 4, score_suffix >= 4) %>% 
    mutate(id = str_remove(basename(file_path), ".hg19.strique.tsv"))
  
  set.seed(666)
  
  fit <- Mclust(df_filtered$count)
  prob <- predict(fit)
  
  df_filtered$allele <- apply(prob$z, 1, which.max)
  
  mode_df <- df_filtered %>%
    group_by(id, allele) %>%
    summarise(
      allele_freq = n(),
      mode_repeat = as.numeric(names(sort(table(count), decreasing = TRUE)[1])),
      repeat_freq = max(table(count)),
      prop = repeat_freq/allele_freq,
      .groups = 'drop'
    ) %>% 
    arrange(desc(allele_freq))

  return(list(mode = mode_df, df = df_filtered))
}

result_list <- lapply(
  setNames(file_paths, str_remove(basename(file_paths), ".hg19.strique.tsv")), 
  function(file_path){
    process_result <- process_file(file_path)
    return(process_result)
})

result_df <- lapply(result_list, function(result) result$df)


result_mode <- lapply(result_list, function(result) result$mode) %>% 
  Reduce(function(...) merge(..., all=T), .) %>% 
  pivot_wider(names_from = allele, values_from = c(mode_repeat, repeat_freq, allele_freq, prop))


result_mode <- merge(FGF14, result_mode, by.x = "barcode", by.y = "id")


write.csv(result_mode, paste0("results/", Sys.Date(), "_FGF14_result.csv"))


```


### Interruptions
```{r}
# omit barcode01 and barcode02 for not having enough read count to support downstream analysis

clusters <- list(
  barcode04 = c(3),
  barcode13 = c(3,5),
  barcode14 = c(4,5),
  barcode15 = c(4,6),
  barcode25 = c(2,5),
  barcode26 = c(3,6),
  barcode27 = c(4,6),
  barcode37 = c(3,6),
  barcode38 = c(3,8),
  barcode39 = c(3,6),
  barcode49 = c(2,5),
  barcode50 = c(4,6),
  barcode51 = c(4,8),
  barcode61 = c(6,8),
  barcode62 = c(1,3),
  barcode63 = c(5),
  barcode73 = c(2,4),
  barcode74 = c(2,3),
  barcode75 = c(2,4),
  barcode85 = c(2,5),
  barcode87 = c(2,6))

# subset clusters from result_df with upstream and downstream from mode (+20 | -20)
lapply(setNames(seq_along(1:length(clusters)), names(clusters)), function(barcode){
    result_df[names(clusters)][[barcode]] %>% 
    filter(allele %in% clusters[[barcode]]) %>% 
    group_by(allele) %>% 
    arrange(count) %>% 
    mutate(allele_ref = paste0("allele_", cur_group_id()),
           mode = as.numeric(names(sort(table(count), decreasing = TRUE)[1])),
           flanking = case_when(count <= mode & count >= mode-20 ~ "upstream",
                                count >= mode & count <= mode+20 ~ "downstream",
                                count >= max(count)-20 ~ "max",
                                TRUE ~ "NA")) %>% 
    ungroup()
}) -> df_subset



# subset fastq id for fetching sequence
lapply(df_subset, function(df){
  name <- df$id %>% unique()
  
  df_a1 <- df %>% 
    filter(allele_ref == "allele_1" & flanking %in% c("upstream", "downstream")) %>%
    select(ID)
  
  df_a2 <- df %>% 
    filter(allele_ref == "allele_2" & flanking %in% c("upstream", "downstream")) %>% 
    select(ID)
  
  write_csv(df_a1, file = paste0("results/A1/", name))
  write_csv(df_a2, file = paste0("results/A2/", name))
})




```


### Figure
```{r}
# summary of the cluster distribution
lapply(df_subset, function(df){
  df %>% 
    group_by(id, allele_ref) %>% 
    summarise(mode = as.numeric(names(sort(table(count), decreasing = TRUE)[1])),
              freq = max(table(count)),
              .groups = 'drop')
}) %>% 
  Reduce(function(...) merge(..., all=T), .) %>% 
  pivot_wider(names_from = allele_ref, values_from = c(mode, freq)) -> mode_df





df_merged <- df_subset %>% Reduce(function(...) merge(..., all=T), .)


ggplot(df_merged, aes(x = count, fill = factor(allele_ref))) +
    geom_density(alpha = 0.5) +
    scale_fill_manual(values = c("red", "blue")) +
    theme_minimal() + 
    facet_wrap(~id, scales = "free")




# Heatmap of all clusters
heatmap_dat <- result_df %>% 
  Reduce(function(...) merge(..., all=T), .) %>% 
  group_by(id, count) %>%
  summarise(freq = n(), .groups = 'drop') %>%
  pivot_wider(names_from = count, values_from = freq) %>% 
  tibble::column_to_rownames("id")

mat <- t(apply(as.matrix(heatmap_dat), 1, function(x) (x - mean(x, na.rm = TRUE))/sd(x, na.rm = TRUE)))

mat <- mat[,order(as.numeric(as.character(colnames(mat))))]

col_fun = colorRamp2(c(-2, 5), c("white", "red"))

num_bins = 50
ha = columnAnnotation(
  foo = anno_mark(
    at = seq(1, ncol(mat) + num_bins, by = num_bins),
    labels = colnames(mat)[seq(1, ncol(mat) + num_bins, by = num_bins)]))

# breaks <- mode_df %>%
#   pivot_longer(cols = c("allele_1", "allele_2")) %>%
#   pull(value) %>%
#   sort %>%
#   unique()

# ha =columnAnnotation(foo = anno_mark(
#   at = c(10,25,60,85,112,123,137,246,270,295,321,366,404,428), 
#   labels = c(10,25,60,85,112,123,137,246,270,295,321,366,404,428)))


heatmap <- ComplexHeatmap::Heatmap(mat,
                                   na_col = "white",
                                   cluster_rows = FALSE, 
                                   cluster_columns = FALSE,
                                   col = col_fun,
                                   top_annotation = ha,
                                   row_split = 1:25,
                                   row_title = NULL,
                                   row_names_side = "left",
                                   show_row_names = TRUE,
                                   show_column_names = FALSE,
                                   name = "z-score")


png("figures/heatmap.png", width = 10, height = 8, units = "in", res = 300)
draw(heatmap)
dev.off()
```

























